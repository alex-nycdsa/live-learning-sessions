{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hints While Model Selecting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract:\n",
    "\n",
    "We will create a classifier to try to identify handwritten digits 0-9 in the infamous [MNIST](https://en.wikipedia.org/wiki/MNIST_database) dataset. Each image is $28\\text{px} \\times 28\\text{px}$, resulting in a total of $784$ pixels per image. We use the 60000 images+labels training set and 10000 images+labels test set which comes standard within the `keras` api through `tensorflow 2.0+`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives:\n",
    "\n",
    "  - Create a few baseline models during EDA\n",
    "  - Describe how observations in our baseline models might guide us towards a more sophisticated model\n",
    "  - Choose between several model types after baseline based on application\n",
    "  - Understand how to create persistence in models and Python objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1: Requisite Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "# import our own helper functions\n",
    "from src.helpers import ravel_images, save_object, open_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST data\n",
    "(Xtrain,ytrain), (Xtest,ytest) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize a few \n",
    "fig, ax = plt.subplots(1,3)\n",
    "ax[0].imshow(Xtrain[0], cmap = 'gray')\n",
    "ax[1].imshow(Xtrain[1], cmap = 'gray')\n",
    "ax[2].imshow(Xtrain[2], cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattening for what follows\n",
    "\n",
    "At this point, `Xtrain/Xtest` are 3-D arrays, where `Xtrain[i]` is the $28 \\times 28$ array with the image. The general technique to coerce the feature tensor into a recognizable 2-D feature matrix is to ravel/flatten each image into a 784-long array into a row. This means that each pixel position in the images is considered its own feature. What will remain after the flattening of the images will be a training feature matrix of dimension $60000 \\times 784$ and testing feature matrix of dimension $10000 \\times 784$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the image tensors into feature matrices\n",
    "Xtrain, Xtest = ravel_images(Xtrain), ravel_images(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (60000, 784) | Testing feature shape: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training shape: {Xtrain.shape} | Testing feature shape: {Xtest.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2: Brainstorm Before Baselining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create data frames/series for `Xtrain` and `ytrain` to allow for some easy exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>px0</th>\n",
       "      <th>px1</th>\n",
       "      <th>px2</th>\n",
       "      <th>px3</th>\n",
       "      <th>px4</th>\n",
       "      <th>px5</th>\n",
       "      <th>px6</th>\n",
       "      <th>px7</th>\n",
       "      <th>px8</th>\n",
       "      <th>px9</th>\n",
       "      <th>...</th>\n",
       "      <th>px775</th>\n",
       "      <th>px776</th>\n",
       "      <th>px777</th>\n",
       "      <th>px778</th>\n",
       "      <th>px779</th>\n",
       "      <th>px780</th>\n",
       "      <th>px781</th>\n",
       "      <th>px782</th>\n",
       "      <th>px783</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   px0  px1  px2  px3  px4  px5  px6  px7  px8  px9  ...  px775  px776  px777  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "1    0    0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "2    0    0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "3    0    0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "4    0    0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "\n",
       "   px778  px779  px780  px781  px782  px783  label  \n",
       "0      0      0      0      0      0      0      5  \n",
       "1      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      4  \n",
       "3      0      0      0      0      0      0      1  \n",
       "4      0      0      0      0      0      0      9  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = pd.DataFrame(Xtrain, columns = [f\"px{i}\" for i in range(784)])\n",
    "ytrain = pd.Series(ytrain, name = 'label')\n",
    "\n",
    "# Get a look at the structuire\n",
    "pd.concat((Xtrain,ytrain), axis = 1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for balance in our target\n",
    "ytrain.value_counts().sort_index().plot(kind = 'bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 71 columns with no non-zero entry.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Considering all the 0s we see, let's look at the variances\n",
    "Xvar = (Xtrain ** 2).sum(axis = 0)\n",
    "print(f\"There are {(Xvar == 0).sum()} columns with no non-zero entry.\")\n",
    "Xvar.hist(bins = 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We also consider what the distribution looks like\n",
    "XhighVar = Xtrain.loc[:,Xvar > 0.5e6]\n",
    "XhighVar.iloc[:,np.random.choice(range(XhighVar.shape[1]), 9)].hist(log = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The brainstorming conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to create a couple baseline classification models to compare before moving into finer tuning, in hopes to get some direction in that tuning. \n",
    "\n",
    "Let us first consider some possible models in our purposes:\n",
    "- `LogisiticRegression`:\n",
    "  - **Pro**: Easy to gauge how good/bad linear decision boundaries might work.\n",
    "  - **Pro**: If linear decision boundaries might be a reasonable choice, we can easily gauge between bias/variance (via `C` in `sklearn`) to think about. \n",
    "  - **Con**: If linear decision boundaries are not a good choice, either we need to do much better feature engineering, or move to a non-linear model.\n",
    "  - **Con**: With many features that aren't very interpretable from the start, injecting domain knowledge into feature engineering can be painful, and we will nonetheless likely need to reduce feature count. \n",
    "  \n",
    "- `LinearDiscriminantAnalysis`:\n",
    "  - **Pro**: Easy to gauge how good/bad linear decision boundaries might work.\n",
    "  - **Pro**: Can perform similarly to LogisticRegression, but has more assumptions from its Bayesian classifier roots. \n",
    "  - **Pro**: We can reduce the feature space (via `n_components`) in a similar, but not exactly the same as PCA procedure that is intrinsict to LDA. \n",
    "  - **Con**: If linear decision boundaries are not a good choice, either we need to do much better feature engineering, or move to a non-linear model.\n",
    "  - **Con**: With many features that aren't very interpretable from the start, injecting domain knowledge into feature engineering can be painful, and we will nonetheless likely need to reduce feature count. \n",
    "  - **Con**: Do we look Gaussian? \n",
    "  \n",
    "- `QuadraticDiscriminantAnalysis`:\n",
    "  - **Pro**: Can create a more complex decision boundary than the linear types whose shape in the feature space is somewhat recognizable.\n",
    "  - **Con**: No bias/variance tradeoff nor many other tuning parameters to consider.\n",
    "  - **Con**: Do we look Gaussian?\n",
    "  \n",
    "- `SVC`:\n",
    "  - **Pro**: Can have non-linear boundaries with some variety. A good step if we want a low-dimensional polynomial boundary, for example. \n",
    "  - **Con**: Training can take a long time. \n",
    "  \n",
    "- `RandomForestClassifier` or `GradientBoostingClassifier`: \n",
    "  - **Pro**: This is a powerful classifier which often works well \"out of the box\". \n",
    "  - **Pro**: As a tree based model, it works well with categorical columns, particularly of ordinal type. \n",
    "  - **Pro**: Many columns can help de-correlate trees to help more with mitigating high variance.\n",
    "  - **Pro and Con**: While we can get a feel for how bad the overfitting is, it usually takes a fair amount of tuning to get a handle on it (`n_estimators`, `max_depth`, `ccp_alpha`, etc). \n",
    "  - **Con**: Random forest is still looking to be highly non-linear and is still possible to overfit. \n",
    "  - **Con**: Lose some ability to gauge where to aim with different models since we don't learn much about decision boundaries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we will do: \n",
    "\n",
    "1. Very basic preprocessing by removing all columns that are constantly 0\n",
    "2. Because we have a reasonably large dataset, we will downsample our training data by a factor of 10 and 5 so that our baseline classifiers train faster and to gauge how important adding more data into the training is to create a good classifier.\n",
    "3. Train a `LogisticRegression` classifier (per downsample) with \"out-of-the-box\" performance, to probe how linear decision boundaries work and where we land in the bias/variance tradeoff.\n",
    "4. Train a `QDA` classifier (per downsample) with \"out-of-the-box\" performance, to probe how the non-linear decision boundaries work and where we land compared to the logistic regression.\n",
    "5. Based on previous two, make a few feature engineering adjustments if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3: First Baseline Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1: Basic preprocessing\n",
    "\n",
    "We've already done some preprocessing by flattening each image, now we remove the columns of all 0s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Remove0VarCols(object):\n",
    "    \n",
    "    def init(self):\n",
    "        self.keep_cols = None\n",
    "        self.been_fit = False\n",
    "    \n",
    "    def fit(self, X):\n",
    "        self.keep_cols = ~((X**2).sum(axis = 0) == 0)\n",
    "        self.been_fit = True\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        if not self.been_fit:\n",
    "            raise Exception(\"Need to fit on training before transforming.\")\n",
    "        return np.array(X)[:, self.keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 713)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train on the training data!\n",
    "rm0var = Remove0VarCols()\n",
    "Xtrain_cl = rm0var.fit(Xtrain).transform(Xtrain)\n",
    "Xtrain_cl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 713)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: once fit, can apply to Xtest without worry\n",
    "rm0var.transform(Xtest).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2: Downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "X10,y10 = resample(Xtrain_cl, ytrain, \n",
    "                   n_samples = Xtrain.shape[0]//10,\n",
    "                   replace = False)\n",
    "X5,y5 = resample(Xtrain_cl, ytrain,\n",
    "                 n_samples = Xtrain.shape[0]//5,\n",
    "                 replace = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3: Logistic Regression Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logr = LogisticRegression(max_iter = 2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logr_cv10_fp = 'output/logr_cv10.pk'\n",
    "logr_cv5_fp = 'output/logr_cv5.pk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression CV for 1/10 downsample loaded\n",
      "Logistic Regression CV for 1/5 downsample loaded\n"
     ]
    }
   ],
   "source": [
    "# Baseline logistic regression on X10, y10\n",
    "logr_cv10 = open_object(logr_cv10_fp)\n",
    "if logr_cv10 is None:\n",
    "    print(\"Recreating logr_cv10\")\n",
    "    logr_cv10 = cross_validate(logr, X10, y10, cv = 5, return_train_score = True)\n",
    "print(\"Logistic Regression CV for 1/10 downsample loaded\")\n",
    "\n",
    "# Baseline logistic regression on X5, y5\n",
    "logr_cv5 = open_object(logr_cv5_fp)\n",
    "if logr_cv5 is None:\n",
    "    print(\"Recreating logr_cv5\")\n",
    "    logr_cv5 = cross_validate(logr, X5, y5, cv = 5, return_train_score = True)\n",
    "print(\"Logistic Regression CV for 1/5 downsample loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filepath output/logr_cv10.pk already exists.\n",
      "Rewrite anyway? ([y] or n): n\n",
      "Filepath output/logr_cv5.pk already exists.\n",
      "Rewrite anyway? ([y] or n): n\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'output/logr_cv5.pk'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Persistence for logistic regression models\n",
    "save_object(logr_cv10, logr_cv10_fp)\n",
    "save_object(logr_cv5, logr_cv5_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10 LogReg Train 1.0 | Test 0.8711666666666668\n",
      "1/5 LogReg Train 1.0 | Test 0.8580833333333334\n"
     ]
    }
   ],
   "source": [
    "print(f\"1/10 LogReg Train {logr_cv10['train_score'].mean()} | Test {logr_cv10['test_score'].mean()}\")\n",
    "print(f\"1/5 LogReg Train {logr_cv5['train_score'].mean()} | Test {logr_cv5['test_score'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lessons:\n",
    "\n",
    "We learned that as is, logistic regression is overfitting and there weren't too many gains by adding in more data. We should then be able to check a range of `C` values which are smaller than $1$ and try again if we want to stick to linear decision boundaries. We should also consider LDA with decreasing number of components or perhaps using PCA before running logistic regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4: QDA Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "\n",
    "qda = QDA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda_cv10_fp = 'output/qda_cv10.pk'\n",
    "qda_cv5_fp = 'output/qda_cv5.pk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA CV for 1/10 downsample loaded\n",
      "QDA CV for 1/5 downsample loaded\n"
     ]
    }
   ],
   "source": [
    "# Baseline QDA on X10, y10\n",
    "qda_cv10 = open_object(qda_cv10_fp)\n",
    "if qda_cv10 is None:\n",
    "    print(\"Recreating qda_cv10\")\n",
    "    qda_cv10 = cross_validate(qda, X10, y10, cv = 5, return_train_score = True)\n",
    "print(\"QDA CV for 1/10 downsample loaded\")\n",
    "\n",
    "# Baseline QDA on X5, y5\n",
    "qda_cv5 = open_object(qda_cv5_fp)\n",
    "if qda_cv5 is None:\n",
    "    print(\"Recreating qda_cv5\")\n",
    "    qda_cv5 = cross_validate(qda, X5, y5, cv = 5, return_train_score = True)\n",
    "print(\"QDA CV for 1/5 downsample loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filepath output/qda_cv10.pk already exists.\n",
      "Rewrite anyway? ([y] or n): n\n",
      "Filepath output/qda_cv5.pk already exists.\n",
      "Rewrite anyway? ([y] or n): n\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'output/qda_cv5.pk'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Persistence for QDA models\n",
    "save_object(qda_cv10, qda_cv10_fp)\n",
    "save_object(qda_cv5, qda_cv5_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10 QDA Train 0.9964166666666665 | Test 0.5254999999999999\n",
      "1/5 QDA Train 0.8408541666666668 | Test 0.6764999999999999\n"
     ]
    }
   ],
   "source": [
    "print(f\"1/10 QDA Train {qda_cv10['train_score'].mean()} | Test {qda_cv10['test_score'].mean()}\")\n",
    "print(f\"1/5 QDA Train {qda_cv5['train_score'].mean()} | Test {qda_cv5['test_score'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lessons: \n",
    "Certainly we have trouble with multicollinearity, so someway to mitigate that would be ideal. We also see the overfitting like before. Note that we're note getting perfect train scores though -- this is likely do to the nature of assumptions over each class, we might have expected this to be bad (why?)! Also, we see an improvement with increasing the number of samples.\n",
    "\n",
    "There is one lesson here though that is useful. If we have a more complicated, non-linear model, the quantity of data may help more than in the linear case. This might suggest to keep non-linear models in mind, but expect better performance at the large-quantity-of-data side of things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4: Some adjustments\n",
    "\n",
    "From our conversation above, I would like to try something else. I would like to try PCA to reduce feature space dimension before jumping into logistic regression. This might help us deal with the over-fitting. Again, we are doing this to probe, so we won't fine tune here too much. We will use the 1/5 downsample here as it provides more observations and might better resemble the full sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise: \n",
    "Why and when might you choose probing PCA over varying `C` in LogisticRegression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filepath output/X5pca_cv.pk already exists.\n",
      "Rewrite anyway? ([y] or n): n\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'output/X5pca_cv.pk'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "# Preprocessing\n",
    "ss = StandardScaler()\n",
    "pca = PCA()\n",
    "# Standardize and apply PCA\n",
    "X5pca = pca.fit_transform(ss.fit_transform(X5))\n",
    "\n",
    "ex_var = [0.8, 0.9, 0.95]\n",
    "\n",
    "X5pca_cv_fp = 'output/X5pca_cv.pk'\n",
    "\n",
    "X5pca_cv = open_object(X5pca_cv_fp)\n",
    "if X5pca_cv is None:\n",
    "    print(\"Recreating X5pca_cv\")\n",
    "    X5pca_cv = []\n",
    "    for ev in ex_var:\n",
    "        Xtemp = X5pca[:,pca.explained_variance_ratio_.cumsum() < ev]\n",
    "        X5pca_cv.append((ev,cross_validate(logr, Xtemp, y5, \n",
    "                                           cv = 5, \n",
    "                                           return_train_score = True)))\n",
    "\n",
    "save_object(X5pca_cv, X5pca_cv_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8,\n",
       "  {'fit_time': array([2.96354198, 2.983073  , 3.14295197, 2.69420576, 2.64024687]),\n",
       "   'score_time': array([0.00208282, 0.00123596, 0.00103879, 0.00100994, 0.00102305]),\n",
       "   'test_score': array([0.90208333, 0.90083333, 0.89416667, 0.89166667, 0.91      ]),\n",
       "   'train_score': array([0.93645833, 0.93666667, 0.93635417, 0.9346875 , 0.93291667])}),\n",
       " (0.9,\n",
       "  {'fit_time': array([4.29148388, 4.34254694, 4.45237923, 4.58346891, 4.47796917]),\n",
       "   'score_time': array([0.00141311, 0.00133777, 0.00135183, 0.00134516, 0.00136089]),\n",
       "   'test_score': array([0.89208333, 0.90041667, 0.89708333, 0.88916667, 0.9025    ]),\n",
       "   'train_score': array([0.94989583, 0.94677083, 0.94729167, 0.9475    , 0.94614583])}),\n",
       " (0.95,\n",
       "  {'fit_time': array([5.89850998, 5.59914994, 6.07005787, 4.97401381, 6.42305207]),\n",
       "   'score_time': array([0.00217128, 0.00155115, 0.00159001, 0.00159383, 0.00180507]),\n",
       "   'test_score': array([0.88125   , 0.89666667, 0.88291667, 0.88083333, 0.89208333]),\n",
       "   'train_score': array([0.96104167, 0.95927083, 0.95989583, 0.960625  , 0.95885417])})]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigate\n",
    "X5pca_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lesson:\n",
    "\n",
    "This helped us a lot with overfitting. We also have a reasonable baseline accuracy performance metric to run off with. It seems we should expect at least a 90% accuracy if we now search deeper! Comparing our train and test scores, it seems that a PCA which keeps between 80%-90% of explained variance does quite well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 4: Moving Up "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's move back to full training data set with the following lessons in mind:\n",
    "\n",
    "- It's easy to overfit -- even with linear decision boundaries -- without some feature engineering.\n",
    "- Scaling and PCA at ~85% explained variance seems to help and create a reasonable model when used before LogisticRegression.\n",
    "- Increasing the amount of data may improve our models performance if we move to slightly more-than-linear decision boundaries.\n",
    "\n",
    "So, now that we have some perspective, my concluding attempt is the following hoping for a better baseline to then judge other probes into a more powerful classifier:\n",
    "\n",
    "Use `SVC` to create a linear and low-D polynomial decision boundaries after scaling and applying PCA with 85% explained variance. (Again, this is just another trial, not complete fine tuning). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the full preprocessing steps we want.\n",
    "\n",
    "# Already done above, but let's not forget\n",
    "rm0var = Remove0VarCols()\n",
    "Xtrain_cl = rm0var.fit(Xtrain).transform(Xtrain)\n",
    "\n",
    "# Standardize and PCA\n",
    "ss = StandardScaler()\n",
    "pca = PCA(n_components=0.85)\n",
    "Xtrain_cl = ss.fit_transform(Xtrain_cl)\n",
    "Xtrain_cl = pca.fit_transform(Xtrain_cl)\n",
    "\n",
    "# Reproduce for test and beyond!\n",
    "def preprocess(X):\n",
    "    retX = rm0var.transform(X)\n",
    "    retX = ss.transform(retX)\n",
    "    return pca.transform(retX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error [Errno 2] No such file or directory: 'output/svc_cv.pk' occurred while trying to open pickle file output/svc_cv.pk.\n",
      "Recreating svc_cv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'output/svc_cv.pk'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "# Create SVC instance\n",
    "svc = SVC()\n",
    "\n",
    "# Set up grid search params\n",
    "kf5 = KFold(n_splits = 5, shuffle = True)\n",
    "svc_params = {'kernel':['poly'], 'degree':[1,2]}\n",
    "\n",
    "# Output file for persistence\n",
    "svc_cv_fp = 'output/svc_cv.pk'\n",
    "\n",
    "# If this grid search has been created, use it!\n",
    "svc_cv = open_object(svc_cv_fp)\n",
    "\n",
    "# If not, let's do it!\n",
    "if svc_cv is None:\n",
    "    print(\"Recreating svc_cv\")\n",
    "    svc_cv = GridSearchCV(estimator=svc, \n",
    "                          param_grid=svc_params,\n",
    "                          return_train_score=True,\n",
    "                          cv = kf5,\n",
    "                          refit = True)\n",
    "    svc_cv.fit(Xtrain_cl, ytrain)\n",
    "    \n",
    "# Save the grid search if not already saved\n",
    "save_object(svc_cv, svc_cv_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With the parameters {'degree': 2, 'kernel': 'poly'}:\n",
      "\t- Best CV score: 0.9713499999999999\n"
     ]
    }
   ],
   "source": [
    "# Investigate\n",
    "print(f\"With the parameters {svc_cv.best_params_}:\")\n",
    "print(f\"\\t- Best CV score: {svc_cv.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hint_lls",
   "language": "python",
   "name": "hint_lls"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
